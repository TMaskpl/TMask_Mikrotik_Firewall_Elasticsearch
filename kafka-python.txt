from kafka import KafkaConsumer
from prometheus_client import start_http_server, Counter, Histogram
from elasticsearch import Elasticsearch, ElasticsearchException
import ssl
import datetime
import os
import time

# ─── Prometheus metryki ─────────────────────────────
MESSAGE_COUNTER = Counter('kafka_messages_total', 'Ilość odebranych wiadomości z Kafki')
MESSAGE_LATENCY = Histogram('kafka_message_latency_seconds', 'Czas przetwarzania wiadomości')
ES_WRITE_TIME = Histogram('elasticsearch_write_duration_seconds', 'Czas trwania zapisu jednej wiadomości do Elasticsearch')

# ─── Start Prometheus endpoint ──────────────────────
start_http_server(8000)

# ─── Elasticsearch klient ───────────────────────────
es = Elasticsearch(['http://localhost:9200'])

# ─── SSL Kafka setup ────────────────────────────────
ssl_context = ssl.create_default_context(
    purpose=ssl.Purpose.SERVER_AUTH,
    cafile='/path/to/ca.cer'
)
ssl_context.load_cert_chain(certfile='/path/to/client.cer', keyfile='/path/to/client.key')

# ─── Kafka Consumer ─────────────────────────────────
consumer = KafkaConsumer(
    'test-topic',
    bootstrap_servers='kafka.example.com:9093',
    security_protocol='SSL',
    ssl_context=ssl_context,
    group_id='python-consumer',
    auto_offset_reset='earliest'
)

print("✅ Kafka Consumer uruchomiony...")

# ─── Pomocnicze ─────────────────────────────────────
def now_str():
    return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

def log_file_path():
    today = datetime.datetime.now().strftime('%Y%m%d')
    log_dir = 'logs'
    os.makedirs(log_dir, exist_ok=True)
    return os.path.join(log_dir, f'{today}.log')

# ─── Funkcja zapisu do logu ─────────────────────────
def write_log(message: str):
    with open(log_file_path(), 'a') as f:
        f.write(f"[{now_str()}] {message}\n")

# ─── Funkcja eksportu do Elasticsearch ──────────────
def export_to_elasticsearch(message: str):
    try:
        now = datetime.datetime.utcnow()
        doc = {
            'timestamp': now.isoformat(),
            'message': message
        }
        with ES_WRITE_TIME.time():  # ⏱️ Pomiar czasu zapisu
            es.index(index='kafka-logs', document=doc)
    except ElasticsearchException as e:
        error_msg = f"⚠️ Błąd eksportu do Elasticsearch: {str(e)}"
        write_log(error_msg)

# ─── Pętla odbioru wiadomości ───────────────────────
for msg in consumer:
    start = time.time()

    text = msg.value.decode('utf-8')
    print(f"[Kafka] {text}")
    write_log(text)
    export_to_elasticsearch(text)

    MESSAGE_COUNTER.inc()
    MESSAGE_LATENCY.observe(time.time() - start)
